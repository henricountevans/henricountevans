{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHrlMRAEfZ3g91kD6StWEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henricountevans/henricountevans/blob/main/YouTube_Transcript_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3syR1QsoPoO",
        "outputId": "15dc8893-4e06-4460-deda-af772647977b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2024.6.2)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.2\n",
            "\n",
            "Processing video: https://www.youtube.com/watch?v=oi6E3tsvelA\n",
            "Source: SABC\n",
            "Video ID: oi6E3tsvelA\n",
            "Processing transcript...\n",
            "Processed 892 lines from this video.\n",
            "\n",
            "Processing video: https://www.youtube.com/watch?v=uTzHc8l3BOM\n",
            "Source: SABC\n",
            "Video ID: uTzHc8l3BOM\n",
            "Processing transcript...\n",
            "Processed 381 lines from this video.\n",
            "\n",
            "Processing video: https://www.youtube.com/watch?v=yNOyu1RMUHY\n",
            "Source: Newzroom Afrika\n",
            "Video ID: yNOyu1RMUHY\n",
            "Processing transcript...\n",
            "Processed 166 lines from this video.\n",
            "\n",
            "All videos processed.\n",
            "\n",
            "Structured dataset saved to /Users/henri-countevans/Documents/YouTube Transcripts Scraper/structured_transcript_dataset.csv\n",
            "\n",
            "First few rows of the dataset:\n",
            "  Source Name     Video ID  Line Number  \\\n",
            "0        SABC  oi6E3tsvelA            1   \n",
            "1        SABC  oi6E3tsvelA            2   \n",
            "2        SABC  oi6E3tsvelA            3   \n",
            "3        SABC  oi6E3tsvelA            4   \n",
            "4        SABC  oi6E3tsvelA            5   \n",
            "\n",
            "                                      Text  \n",
            "0   but here's the lead story this morning  \n",
            "1   the eff is calling for a new statement  \n",
            "2  of intent on the government of national  \n",
            "3      Unity which excludes the da and the  \n",
            "4    freedom front plus this call comes as  \n",
            "\n",
            "Dataset summary:\n",
            "       Line Number\n",
            "count  1439.000000\n",
            "mean    336.977067\n",
            "std     255.153452\n",
            "min       1.000000\n",
            "25%     120.500000\n",
            "50%     277.000000\n",
            "75%     532.500000\n",
            "max     892.000000\n",
            "\n",
            "Total number of lines across all transcripts: 1439\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install required libraries (if not already installed)\n",
        "!pip install youtube_transcript_api pandas\n",
        "\n",
        "# Cell 2: Import required libraries\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from youtube_transcript_api.formatters import TextFormatter\n",
        "\n",
        "# Cell 3: Define functions\n",
        "def get_video_id(url):\n",
        "    \"\"\"Extract video ID from YouTube URL.\"\"\"\n",
        "    if \"youtu.be\" in url:\n",
        "        return url.split(\"/\")[-1]\n",
        "    elif \"youtube.com\" in url:\n",
        "        return url.split(\"v=\")[1].split(\"&\")[0]\n",
        "    else:\n",
        "        raise ValueError(\"Invalid YouTube URL\")\n",
        "\n",
        "def fetch_transcript(video_id):\n",
        "    \"\"\"Fetch the transcript for a given video ID.\"\"\"\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        return transcript  # Return the raw transcript data\n",
        "    except TranscriptsDisabled:\n",
        "        print(\"Transcripts are disabled for this video.\")\n",
        "        return None\n",
        "    except NoTranscriptFound:\n",
        "        print(\"No transcript found for this video.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Cell 4: Main execution\n",
        "# List of YouTube URLs with their corresponding source names\n",
        "video_data = [\n",
        "    {\"url\": \"https://www.youtube.com/watch?v=oi6E3tsvelA\", \"source\": \"SABC\"},\n",
        "    {\"url\": \"https://www.youtube.com/watch?v=uTzHc8l3BOM\", \"source\": \"SABC\"},\n",
        "    {\"url\": \"https://www.youtube.com/watch?v=yNOyu1RMUHY\", \"source\": \"Newzroom Afrika\"}\n",
        "]\n",
        "\n",
        "export_folder = \"/Users/henri-countevans/Documents/YouTube Transcripts Scraper\"\n",
        "\n",
        "# Ensure the export folder exists\n",
        "os.makedirs(export_folder, exist_ok=True)\n",
        "\n",
        "# Create a list to store all transcript data\n",
        "all_transcript_data = []\n",
        "\n",
        "for video in video_data:\n",
        "    try:\n",
        "        url = video[\"url\"]\n",
        "        source = video[\"source\"]\n",
        "        video_id = get_video_id(url)\n",
        "        print(f\"\\nProcessing video: {url}\")\n",
        "        print(f\"Source: {source}\")\n",
        "        print(f\"Video ID: {video_id}\")\n",
        "\n",
        "        transcript = fetch_transcript(video_id)\n",
        "\n",
        "        if transcript:\n",
        "            print(\"Processing transcript...\")\n",
        "\n",
        "            # Process each line of the transcript\n",
        "            for i, entry in enumerate(transcript, 1):\n",
        "                all_transcript_data.append({\n",
        "                    \"Source Name\": source,\n",
        "                    \"Video ID\": video_id,\n",
        "                    \"Line Number\": i,\n",
        "                    \"Text\": entry[\"text\"]\n",
        "                })\n",
        "\n",
        "            print(f\"Processed {len(transcript)} lines from this video.\")\n",
        "        else:\n",
        "            print(\"Failed to fetch transcript for this video.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Error with URL {url}: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred with URL {url}: {str(e)}\")\n",
        "\n",
        "print(\"\\nAll videos processed.\")\n",
        "\n",
        "# Create a DataFrame from the transcript data\n",
        "df = pd.DataFrame(all_transcript_data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_filename = \"structured_transcript_dataset.csv\"\n",
        "csv_filepath = os.path.join(export_folder, csv_filename)\n",
        "df.to_csv(csv_filepath, index=False)\n",
        "print(f\"\\nStructured dataset saved to {csv_filepath}\")\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nDataset summary:\")\n",
        "print(df.describe())\n",
        "print(f\"\\nTotal number of lines across all transcripts: {len(df)}\")"
      ]
    }
  ]
}